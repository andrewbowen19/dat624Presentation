---
title: 'Time Series Decomposition'
subtitle: "DATA 624 Presentation"
author: "Andrew Bowen, Josh Forster, John Cruz"
date: "2024-02-04"
output: 
  ioslides_presentation:
    smaller: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r libraries, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tsibble)
library(feasts)
library(kableExtra)
library(arrow)
```
## What is a time series?

- A time series is a group of observations of a data point that are tracked over time
    - Trend/Cycle
    - Seasonal
    - Remainder
- This information can be tracked at several levels of time (e.g. annual, quarterly, monthly, etc.)
- Economic measures are generally the most common metrics tracked and discussed, but any area with relevant data points can be analyzed

## Why is Time Series Decomposition relevant?

- It is helpful to understand the patterns that make up trends/cycles vs seasonal behaviors.
- Different modeling techniques can be applied based on the knowledge of how the primary components interact with one another.
- If you are interested in making inferences on this data, it is a good starting point to get a better understanding of these elements

## Our Dataset
- We pulled [data representing Citibike rides in Jersey City during Q4 of 2023](https://s3.amazonaws.com/tripdata/index.html)

```{r data-read-in, warning=FALSE, message=FALSE}
# Read in our dataset and store it as a `tsibble` obejct
df <- read_parquet("data/rides_per_hour.parquet")

#df <- read_parquet("data/rides_per_hour.parquet")
rides <- df %>% as_tsibble(index=start_time, key=c(start_station_name, rideable_type, member_casual))

# Fill NAs with 0s
rides <- rides |> fill_gaps() |> mutate(number_of_rides = replace_na(number_of_rides, 0))
head(rides)
```


## Viewing our Data
It's always a good idea to plot your time series prior to any sort of decomposition
```{r plot-top-stations, echo=FALSE}
# Select out top station
top_stations <- rides %>% 
  group_by(start_station_name) %>% 
  summarise(number_of_rides = sum(number_of_rides)) %>% 
  filter(start_station_name == "Columbus Drive")

# Plot 
autoplot(top_stations, number_of_rides) + 
  labs(x="Start Time",
       y="Number of Rides",
       title="Columbus Drive (Jersey City) Citi Bike Rides: Fall 2024")
```


## Plotting Seasonality
Below is the seasonal plot of our data for a daily period. We see a higher number of rides around 5-6pm, when many people are commuting.
```{r}
# Seasonal plot of a daily period
gg_season(top_stations, number_of_rides, period="day")
```


## Lag Plots
- Lag plots can be an effective way to display autocorrelation and seasonal cycles within your TS

```{r lag-plots-monthly, echo=FALSE, warning=FALSE}
top_stations %>% gg_lag(number_of_rides, period=12, geom = c("point"), lags=1:12)
```


## Lag Plots (cont.)
Below we see a plot of weekly lags. We don't see a ton of structure here indicating weaker relationships between a value and its lagged values
```{r lag-plots-weekly, echo=FALSE, warning=FALSE}
top_stations %>% gg_lag(number_of_rides, period=7, geom = c("point"), lag=1:7)
```




## Time Series Components
- Our example time-series data has two seasonal periods: daily and weekly
- We can plot the different `components` of our decomposed series via the `autoplot` function

```{r plot-components, echo=FALSE}
# Plotting different components of our TS
decomp <- top_stations %>% 
  model(stl = STL(number_of_rides))

components(decomp) %>% autoplot() + 
  labs(x="Start Time",
       y="Number of Rides", 
       title="Citibike Rides in Jersey City: Time-series Components")
```

## Time Series Components

- We can also seasonally-adjust our data easily in the `fabletools` package
```{r seasonal-adjust, echo=FALSE}
# Correct any negative values since number of rides has a min of 0
seasonal_adjust <- components(decomp) %>% mutate(season_adjust = ifelse(season_adjust < 0, 0, season_adjust))

seasonal_adjust %>%
  as_tsibble() %>%
  autoplot(number_of_rides, colour = "gray") +
  geom_line(aes(y=season_adjust), colour = "blue") +
  labs(x="Start Time", y = "Rides",
       title = "Seasonally-adjusted # of Citibike Rides: Columbus Drive in Jersey City - Fall 2024")
```


## Viewing Daily Rides by Membership

```{r daily-rides, echo=FALSE, results = FALSE}
daily_member_rides <- 
  rides %>%
  group_by_key() %>%
  index_by(datetime = ~as_date(.)) %>%
  summarise(total_rides = sum(number_of_rides))
head(daily_member_rides)
```



## Follow Up

```{r plot-daily-rides, echo=FALSE, warning=FALSE, fig.height=3}
daily_total_rides <-
  daily_member_rides %>%
  group_by(member_casual) %>% 
  summarise(total_member_rides = sum(total_rides))
daily_total_rides |> 
  ggplot(aes(x=datetime, y=total_member_rides, colour=member_casual, label=member_casual)) +
  geom_line() +
  geom_text(data = . %>% 
               group_by(member_casual) %>%
               filter(total_member_rides == max(total_member_rides, na.rm = TRUE)) %>%
               arrange(desc(total_member_rides)) %>%
               head(2), 
             aes(label = paste0(member_casual, " (", total_member_rides,")")),
            hjust="left") + 
  theme_bw() +
  theme(legend.position="none") +
  labs(title = "Daily Citi Bike Rides in Jersey City, NJ",
       y = "Total Rides", x="") +
  scale_color_manual(values=c("#F28E2B", "#4E79A7"))
```

```{r table-daily-rides, echo=FALSE}
total_member_rides <-
  daily_total_rides %>%
  as_tibble() %>%
  group_by(member_casual) %>%
  summarise(total_member_rides = sum(total_member_rides, na.rm = TRUE)) %>%
  arrange(desc(total_member_rides))

member_rides <-
  daily_total_rides %>%
  group_by(member_casual) %>%
  filter(total_member_rides == max(total_member_rides, na.rm = TRUE)) %>%
  arrange(desc(total_member_rides)) %>%
  rename(max_station_rides = total_member_rides)

merge_table <-
  member_rides |>
  left_join(total_member_rides, by=join_by(member_casual)) |>
  arrange(desc(max_station_rides))

kbl(merge_table, 
    caption = "Membership Type", 
    col.names = c("Type", "Date", "Max Daily Rides", "Total Rides")) |>
  kable_styling("condensed")
```


## Moving Averages

- Useful for "smoothing" data to reduce seasonal fluctuations and discover the trend-cycle. 

$$
T_t = \sum_{j=-k}^{k} y_{t+j}
$$

$$k = \frac {(m-1)}{2}$$

$$a_j = a_{-j}$$

## Calculating for 01/04/2023

$$7-MA = \sum_{j=-3}^{3} y_{t+j}$$

```{r moving-averages-head}
casual_rides <-
  daily_total_rides |>
  filter(member_casual == "casual") |>
  mutate(
    `7-MA` = slider::slide_dbl(total_member_rides, mean,
                .before = 3, .after = 3, .complete = TRUE)
  )

head(casual_rides, 7) |>
  kbl() |>
  kable_styling("condensed") |>
  row_spec(4, bold = T, color = "white", background = "#D7261E")
```

## Calculating for 12/28/2023

```{r moving-averages-tail}
tail(casual_rides, 7) |>
  kbl() |>
  kable_styling("condensed") |>
  row_spec(4, bold = T, color = "white", background = "#D7261E")
```

---

```{r plot-ma, warning=FALSE}
casual_rides |>
  autoplot(total_member_rides, colour = "gray") +
  geom_line(aes(y = `7-MA`), colour = "#D55E00") +
  labs(y = "Total Rides",
       title = "7-MA: Riders without Membership")
```

## Moving Average is Even Ordered

```{r hourly-rides, echo=FALSE, results = FALSE}
hourly_member_rides <- 
  rides %>%
  group_by_key() %>%
  index_by(datetime = ~round_date(., "hour")) %>%
  summarise(total_rides = sum(number_of_rides))
head(hourly_member_rides)
```

```{r plot-hourly-rides, echo=FALSE, warning=FALSE, fig.height=3}
hourly_total_rides <-
  hourly_member_rides %>%
  group_by(member_casual) %>% 
  summarise(total_member_rides = sum(total_rides))

hourly_total_rides |> 
  ggplot(aes(x=datetime, y=total_member_rides, colour=member_casual, label=member_casual)) +
  geom_line() +
  geom_text(data = . %>% 
               group_by(member_casual) %>%
               filter(total_member_rides == max(total_member_rides, na.rm = TRUE)) %>%
               arrange(desc(total_member_rides)) %>%
               head(2), 
             aes(label = paste0(member_casual, " (", total_member_rides,")")),
            hjust="left") + 
  theme_bw() +
  theme(legend.position="none") +
  labs(title = "Hourly Citi Bike Rides in Jersey City, NJ",
       y = "Total Rides", x="") +
  scale_color_manual(values=c("#F28E2B", "#4E79A7"))
```

```{r table-qtr-rides, echo=FALSE}
total_member_rides <-
  hourly_total_rides %>%
  as_tibble() %>%
  group_by(member_casual) %>%
  summarise(total_member_rides = sum(total_member_rides, na.rm = TRUE)) %>%
  arrange(desc(total_member_rides))

member_rides <-
  hourly_total_rides %>%
  group_by(member_casual) %>%
  filter(total_member_rides == max(total_member_rides, na.rm = TRUE)) %>%
  arrange(desc(total_member_rides)) %>%
  rename(max_station_rides = total_member_rides)

merge_table <-
  member_rides |>
  left_join(total_member_rides, by=join_by(member_casual)) |>
  arrange(desc(max_station_rides))

kbl(merge_table, 
    caption = "Membership Type", 
    col.names = c("Type", "Hour", "Max Daily Rides", "Total Rides")) |>
  kable_styling("condensed")
```

## Calculating for 01/01/2023 12:00:00 PM

```{r moving-averages-head-even}
even_casual_rides <-
  hourly_total_rides |>
  filter(member_casual == "casual") |>
  mutate(
    `24-MA` = slider::slide_dbl(total_member_rides, mean,
                .before = 11, .after = 12, .complete = TRUE),
    `2x24-MA` = slider::slide_dbl(`24-MA`, mean,
                .before = 1, .after = 0, .complete = TRUE)
  )

even_casual_rides[8:16, ] |>
  kbl() |>
  kable_styling("condensed") |>
  row_spec(6, bold = T, color = "white", background = "#D7261E")
```

---

```{r plot-ma-24, warning=FALSE}
even_casual_rides |>
  autoplot(total_member_rides, colour = "gray") +
  geom_line(aes(y = `2x24-MA`), colour = "#D55E00") +
  labs(y = "Total Rides",
       title = "2x24-MA: Riders without Membership")
```

## Classical Decomposition Methods
- Additive Decomposition: $Y = S + T + C$
  - Calculate Trend-Cycle Component $T_t$ = 2 x m-MA (even) or m-MA (odd)
  - Detrended Series = $y_t - T_t$
  - Seasonal Series = Average of the seasonal component (month, quarter, etc)
  - Remainder (Irregular) Series = $R_t = y_t - T_t - S_t$
  
---

```{r additive-decomp, warning=FALSE}
# Additive decomposition first
casual_rides %>% model(
    classical_decomposition(total_member_rides, type = "additive")
  ) %>% 
  components() %>% 
  autoplot() +
  labs(title = "Classical Additive Decomposition of Citibike Rides")
```

---

- Multiplicative: $Y = S * T * C$
  - Calculate Trend-Cycle Component $T_t$ = 2 x m-MA (even) or m-MA (odd)
  - Detrended Series = $\frac{y_t}{T_t}$
  - Seasonal Series = Average of the seasonal component (month, quarter, etc)
  - Remainder (Irregular) Series = $R_t = \frac{y_t}{T_t * S_t}$

```{r multiplicative-decomp, warning=FALSE}
# Multiplicative decomposition first
casual_rides %>% model(
    classical_decomposition(total_member_rides, type = "multiplicative")
  ) %>% 
  components() %>% 
  autoplot() +
  labs(title = "Classical Multiplicative Decomposition of Citibike Rides")
```

## Classical Decomposition Drawbacks

- The estimated trend-cycle is missing for the first and last few observations
- The trend cycle can be smoothed too much with large, fast peaks and valleys
- We assume the seasonality holds true between each year
- It is not robust to valid outliers such as natural disasters or economic changes. 

## STL Decomposition
- *Seasonal and Trend Decomposition using LOESS*
- Use `trend` and `season` parameters to control how rapidly seasonality and trend change

```{r stl-decomp, echo=FALSE, warning=FALSE}
# Plot STL decomposition of our time series
casual_rides |>
  model(
    STL(total_member_rides ~ trend(window = 31) +
                   season(window = "periodic"),
    robust = TRUE)) |>
  components() |>
  autoplot()
```

## Pros and Cons of STL Decomposition

#### Pros
- Can handle different types of seasonality well (not just  monthly/quarterly)
- User has a lot of control over parameters (smoothness, windowing, etc)
- Robust to outlier values


#### Cons
- Only can be used with additive decomposition
- Doesn't handle calendar variation automatically
  - [Here's an article with a newer method that handles multiple seasonalities well!](https://www.sciencedirect.com/science/article/abs/pii/S0096300322004726)

#### Alternative Approaches

- Since economists spend most of their time analyzing time series data, they have come up with additional methods
    - X11/SEATS
        - Primarily handles monthly and quarterly data, but allows for incorporation of holidays. 
        - Variation of the seasonal period is allowed
    - DSA
        - German Bank established this method to handle daily data
        - Combines STL on multiple seasonal components and ARIMA for additional handling of outliers and calendar adjustments

## Sources Used

- Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on February 16th, 2024
- Oscar Trull, J. Carlos García-Díaz, A. Peiró-Signes, Multiple seasonal STL decomposition with discrete-interval moving seasonalities, Applied Mathematics and Computation, Volume 433, 2022, 127398, ISSN 0096-3003, [https://doi.org/10.1016/j.amc.2022.127398](https://www.sciencedirect.com/science/article/pii/S0096300322004726)
- https://cran.r-project.org/web/packages/dsa/dsa.pdf
- https://towardsdatascience.com/seasonal-adjustment-of-daily-time-series-1bd2aa9b096d


